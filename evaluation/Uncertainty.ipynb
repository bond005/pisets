{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "from typing import Any\n",
    "import dataclasses\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, pipeline, Pipeline,\n",
    "    WhisperProcessor, WhisperForConditionalGeneration\n",
    ")\n",
    "import pysrt\n",
    "from IPython.display import clear_output\n",
    "import IPython.display\n",
    "import librosa\n",
    "\n",
    "from asr.asr import (\n",
    "    initialize_model_for_speech_segmentation,\n",
    "    initialize_model_for_speech_classification,\n",
    "    initialize_model_for_speech_recognition,\n",
    "    transcribe\n",
    ")\n",
    "from asr.lm import SequenceScore\n",
    "from asr.comparison import TokenizedText, MultipleTextsAlignment, filter_correction_suggestions\n",
    "from asr.whisper_scores import whisper_pipeline_transcribe_with_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    load_dataset('dangrebenkin/long_audio_youtube_lectures')\n",
    "    .cast_column('audio', Audio(sampling_rate=16_000))\n",
    "    ['train']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[2]\n",
    "waveform = sample['audio']['array']\n",
    "sample['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = initialize_model_for_speech_segmentation('ru', 'bond005/wav2vec2-large-ru-golos')\n",
    "whisper_pipeline = initialize_model_for_speech_recognition('ru', 'openai/whisper-large-v3')\n",
    "\n",
    "results = transcribe(\n",
    "    waveform,\n",
    "    segmenter=segmenter,\n",
    "    voice_activity_detector=lambda audio: [{'score': 1, 'label': 'Speech'}],\n",
    "    asr=lambda audio: {'text': 'none'},\n",
    "    min_segment_size=1,\n",
    "    max_segment_size=20,\n",
    ")\n",
    "\n",
    "tokenized_segments = []\n",
    "scores_per_word = []\n",
    "\n",
    "for segment in tqdm(results):\n",
    "    waveform_segment = waveform[int(segment.start * 16_000):int(segment.end * 16_000)]\n",
    "    tokenized_text_for_segment, _, scores_for_segment = (\n",
    "        whisper_pipeline_transcribe_with_word_scores(waveform_segment, whisper_pipeline)\n",
    "    )\n",
    "    tokenized_segments.append(tokenized_text_for_segment)\n",
    "    scores_per_word += scores_for_segment\n",
    "\n",
    "tokenized_text = TokenizedText.concatenate(tokenized_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.tokenization_whisper import bytes_to_unicode\n",
    "\n",
    "\n",
    "feature_extractor = whisper_pipeline.feature_extractor\n",
    "tokenizer = whisper_pipeline.tokenizer\n",
    "model = whisper_pipeline.model\n",
    "generate_kwargs = whisper_pipeline._forward_params\n",
    "\n",
    "inputs = feature_extractor(\n",
    "    waveform_segment,\n",
    "    return_tensors='pt',\n",
    "    sampling_rate=16_000,\n",
    ").to(model.device, model.dtype)\n",
    "result = model.generate(\n",
    "    **inputs,\n",
    "    **generate_kwargs,\n",
    "    return_dict_in_generate=True,\n",
    "    return_token_timestamps=True,\n",
    ")\n",
    "\n",
    "# convert token ids and logits to numpy\n",
    "token_ids = result['sequences'][0].cpu().numpy()\n",
    "logits = torch.nn.functional.log_softmax(torch.stack(result['scores']), dim=-1).cpu().numpy()\n",
    "\n",
    "# skip start special tokens to align with logits\n",
    "token_ids = token_ids[-len(logits):]\n",
    "\n",
    "# skip all special tokens\n",
    "is_special = np.array([id in tokenizer.all_special_ids for id in token_ids])\n",
    "token_ids = token_ids[~is_special]\n",
    "logits = logits[~is_special]\n",
    "\n",
    "score_per_token = np.array([float(l[0, token_id]) for token_id, l in zip(token_ids, logits)])\n",
    "\n",
    "# reproducing whisper bpe decoding\n",
    "byte_decoder = {v: k for k, v in bytes_to_unicode().items()}\n",
    "bytes_list_per_token = [\n",
    "    [byte_decoder[x] for x in bytes_str]\n",
    "    for bytes_str in tokenizer.convert_ids_to_tokens(token_ids)\n",
    "]\n",
    "\n",
    "# searching for token positions in the text\n",
    "token_end_positions = []\n",
    "for i in range(len(bytes_list_per_token)):\n",
    "    concatenated_bytes = sum(bytes_list_per_token[:i + 1], [])\n",
    "    try:\n",
    "        text = bytearray(concatenated_bytes).decode('utf-8', errors='strict')\n",
    "        token_end_positions.append(len(text))\n",
    "    except UnicodeDecodeError:\n",
    "        token_end_positions.append(None)  # not a full utf-8 charachter\n",
    "\n",
    "assert text == tokenizer.decode(token_ids, clean_up_tokenization_spaces=False)\n",
    "\n",
    "# cleaning up tokenization spaces, shifting token_end_positions\n",
    "# (see .clean_up_tokenization() in PreTrainedTokenizerBase)\n",
    "if tokenizer.clean_up_tokenization_spaces:\n",
    "    for replace_from in [\" .\", \" ?\", \" !\", \" ,\", \" ' \", \" n't\", \" 'm\", \" 's\", \" 've\", \" 're\"]:\n",
    "        replace_to = replace_from.strip()\n",
    "        while (start_pos := text.find(replace_from)) != -1:\n",
    "            delta_len = len(replace_to) - len(replace_from)\n",
    "            text = text[:start_pos] + replace_to + text[start_pos + len(replace_from):]\n",
    "            token_end_positions = [\n",
    "                (\n",
    "                    token_end_pos\n",
    "                    if token_end_pos <= start_pos\n",
    "                    else token_end_pos + delta_len\n",
    "                )\n",
    "                for token_end_pos in token_end_positions\n",
    "            ]\n",
    "\n",
    "    assert text == tokenizer.decode(token_ids)\n",
    "\n",
    "# tokenizing the text\n",
    "tokenized_text = TokenizedText.from_text(text)\n",
    "\n",
    "# matching words and tokens\n",
    "tokens_range_per_word = []\n",
    "for word in tokenized_text.get_words():\n",
    "    first_token_idx = None  # first token of the word, inclusive\n",
    "    for token_idx, token_end_pos in enumerate(token_end_positions):\n",
    "        if token_end_pos is None:\n",
    "            continue\n",
    "        if token_end_pos > word.start and first_token_idx is None:\n",
    "            first_token_idx = token_idx\n",
    "        if token_end_pos >= word.stop:\n",
    "            break\n",
    "    tokens_range_per_word.append((first_token_idx, token_idx + 1))\n",
    "\n",
    "tokens_per_word = [\n",
    "    [\n",
    "        bytearray(b).decode('utf-8', errors='replace')\n",
    "        for b in bytes_list_per_token[start_token_idx:end_token_idx]\n",
    "    ]\n",
    "    for start_token_idx, end_token_idx in tokens_range_per_word\n",
    "]\n",
    "\n",
    "token_scores_per_word = [\n",
    "    list(score_per_token[start_token_idx:end_token_idx])\n",
    "    for start_token_idx, end_token_idx in tokens_range_per_word\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytearray(sum(bytes_list_per_token, [])).decode('utf-8', errors='strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(token_ids, skip_special_tokens=False, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('/home/oleg/pisets_test_results_with_scores')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filepath = output_dir / f'{sample[\"name\"]} Pisets WhisperV3 no-VAD (segments 1s-20s) with scores.json'\n",
    "\n",
    "with open(filepath, 'w') as f:\n",
    "    json.dump({\n",
    "        'tokenized_text': dataclasses.asdict(tokenized_text),\n",
    "        'scores_per_word': scores_per_word,\n",
    "    }, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/home/oleg/pisets_test_results_with_scores/savvateev Pisets WhisperV3 no-VAD (segments 1s-20s) with scores.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subsets(elements: list[Any]):\n",
    "    \"\"\"\n",
    "    Returns all subsets of a list.\n",
    "    ```\n",
    "    get_all_subsets([1, 2, 3])\n",
    "    >>> [(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return sum((\n",
    "        [list(x) for x in combinations(elements, r)]\n",
    "        for r in range(len(elements) + 1)\n",
    "    ), [])\n",
    "\n",
    "base = transcriptions['galore']['whisperV3_long_segments_ru']\n",
    "additional = transcriptions['galore']['w2v2_golos_lm']\n",
    "truth = transcriptions['galore']['truth']\n",
    "\n",
    "MultipleTextsAlignment.from_strings(truth, base).wer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_uncertain = MultipleTextsAlignment.from_strings(base, additional).get_uncertainty_mask()\n",
    "print('Uncertain words ratio', is_uncertain.mean())\n",
    "MultipleTextsAlignment.from_strings(truth, base).wer(uncertainty_mask=is_uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = MultipleTextsAlignment.from_strings(base, additional)\n",
    "orig_indices_to_resolve = filter_correction_suggestions(alignment, skip_word_form_change=False)\n",
    "indices_to_resolve = orig_indices_to_resolve.copy()\n",
    "indices_accepted = []\n",
    "\n",
    "# print(alignment.substitute(show_in_braces=indices_to_resolve))\n",
    "\n",
    "depth = 2\n",
    "\n",
    "context_before = 100\n",
    "context_after = 100\n",
    "\n",
    "while len(indices_to_resolve):\n",
    "    print(f'{len(indices_to_resolve)} indices remaining')\n",
    "\n",
    "    indices = indices_to_resolve[:depth]\n",
    "\n",
    "    variants: list[list[int]] = get_all_subsets(indices)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for indices_to_consider in get_all_subsets(indices):\n",
    "        text = alignment.substitute(replace=indices_accepted + indices_to_consider)\n",
    "\n",
    "        start_idx = alignment.matches[indices[0]].char_start1\n",
    "        end_idx = alignment.matches[indices[-1]].char_end1 + len(text) - len(alignment.text1.text)\n",
    "\n",
    "        start_idx -= context_before\n",
    "        end_idx += context_after\n",
    "\n",
    "        start_idx = np.clip(start_idx, 0, len(text))\n",
    "        end_idx = np.clip(end_idx, 0, len(text))\n",
    "\n",
    "        text = text[start_idx:end_idx]\n",
    "\n",
    "        scores[tuple(indices_to_consider)] = {\n",
    "            'score': sequence_score(text),\n",
    "            'text' : text\n",
    "        }\n",
    "\n",
    "    print([x['score'] for x in scores.values()])\n",
    "\n",
    "    best_option = max(scores, key=lambda k: scores[k]['score'])\n",
    "\n",
    "    should_accept_index = indices[0] in best_option\n",
    "\n",
    "    if should_accept_index:\n",
    "        indices_accepted.append(indices[0])\n",
    "    \n",
    "    indices_to_resolve = indices_to_resolve[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = alignment.substitute(replace=indices_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultipleTextsAlignment.from_strings(truth, corrected).wer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_uncertain = MultipleTextsAlignment.from_strings(base, corrected).get_uncertainty_mask()\n",
    "print('Uncertain words ratio', is_uncertain.mean())\n",
    "MultipleTextsAlignment.from_strings(truth, base).wer(uncertainty_mask=is_uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = MultipleTextsAlignment.from_strings(base, additional)\n",
    "\n",
    "print(alignment.substitute(\n",
    "    show_in_braces=[i for i, op in enumerate(alignment.matches) if not op.is_equal]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = MultipleTextsAlignment.from_strings(truth, base)\n",
    "\n",
    "print(alignment.substitute(\n",
    "    show_in_braces=[i for i, op in enumerate(alignment.matches) if not op.is_equal]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = MultipleTextsAlignment.from_strings(base, corrected)\n",
    "\n",
    "print(alignment.substitute(\n",
    "    show_in_braces=filter_correction_suggestions(alignment, skip_word_form_change=False)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(alignment.substitute(\n",
    "#     show_in_braces=orig_indices_to_resolve,\n",
    "#     pref_second=indices_accepted,\n",
    "#     pref_first=set(orig_indices_to_resolve) - set(indices_accepted),\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I have two speech recognition models (the first model is usually better) and compare their predictions. In the following text, the disagreement between models is highlighted in braces.\n",
    "\n",
    "- {aaa|bbb} means that the second model wants to replace \"aaa\" with \"bbb\"\n",
    "- {+xx} means that the second model wants to insert \"xx\" into the first model predictions\n",
    "- {yy} means that the second model wants to remove \"yy\" from the first model predictions\n",
    "\n",
    "Based on linguistic knowledge and common sense, please resolve the disagreement and write the final transcription without braces.\n",
    "\n",
    "The text:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
